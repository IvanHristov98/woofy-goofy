<!DOCTYPE html>
<html>
<head>
    <title>Sounds</title>
    <link rel="stylesheet" type="text/css" href="css/style.css">

    <script src="https://cdn.jsdelivr.net/gh/google/code-prettify@master/loader/run_prettify.js"></script>
</head>
<body>
    <div id="page">
        <h1>Въведение в аудио филтрите за уеб</h1><hr/>
        <h2>Дефиниция</h2>
        <p>Аудио wtf mate  филтри в уеб наричаме библиотеки, които се използват за създаване и манипулация на звук в уеб (откъдето идва и името филтри).</p>

        <h2>Web Audio API</h2>
        <p>Най-разпространената имплементация е библиотеката Web Audio API. Тя включва изпълнение на аудио операции в <b>контекст</b>. Аудио операциите се извършват посредством audio node-ове, свързани помежду си оформяйки audio routing graph. 
            <ul>Има няколко типа върхове в този граф:
                <li>sources (източници) - това са върхове, генериращи аудио. Пример за такъв е Oscillator, като такива могат да са дори &lt;audio&gt; елементи в една html страница.</li>
                <li>filters - това са тези върхове, които изменят аудиото, което преминава през тях и го предават на други върхове след тях.</li>
                <li>destinations - това е крайната точка, където бива запращано аудиото. Това обичайно са хардуерните устройства произвеждащи звук.</li>
            </ul>
        </p>
        <p>Последователността от ефекти при Web Audio API може да се изобрази по следния начин:
            <img src="img/web_audio_flow.svg"/>
        </p>
        <p>Звукът минава през върховете на графа под формата на поток, като един поток може да се състои от няколко канала. В зависимост от броя на каналите може да се поддържа различен тип аудио структура, като например <b>моно, стерео, quad и 5.1</b>.</p>
        <h2>Аудио буфери, извадки и канали</h2>
        <p>В природата звукът може да се разглежда като непрекъсната функция. На практика това няма как да се представи директно в един компютър и поради това се налага разбиването на непрекъсната функция на малки парчета. Това е така наречение процес на дигитализация. В Web Audio API този процес на дигитализация наричаме sampling. Така един времеви интервал от звук, може да се разбие на <b>n</b> на брой парчета, като всяко от тях е число в масив.</p>
        <p>В момент <b>T</b> във всеки канал от потока на звука има извадка. Групата от тези извадки наричаме sample frame на момент <b>T</b>. Също така sample frame-а е n-мерен вектор, където n е броят на каналите.</p>
        <p>Този масив от frame-ове се пази в AudioBuffer, който се характеризира с дължина (бр. sample frame-ове) и честота на извадките (sample rate), което е бр. на sample frame-овете пуснати за секунда. Например един стерео буфер може да бъде представен по следния начин:
            <img src="img/audio_buffer.png"/>
        </p>
        
        <h2>Аудио канали</h2>
        <p>Има различни видове аудио буфери, като най-често използваните (и тези поддържани от Web Audio API) са поставени в таблицата отдолу.</p>

        <table>
            <tr>
                <th>Аудио буфер</th>
                <th>Канали</th>
            </tr>
            <tr>
                <td>Моно</td>
                <td><text class="mark">0: M: mono</text></td>
            </tr>
            <tr>
                <td>Стерео</td>
                <td>
                    <text class="mark">0: L: left</text><br/>
                    <text class="mark">1: R: right</text>
                </td>
            </tr>
            <tr>
                <td>Quad</td>
                <td>
                    <text class="mark">0: L: left</text><br/>
                    <text class="mark">1: R: right</text><br/>
                    <text class="mark">2: SL: surround left</text><br/>
                    <text class="mark">3: SR: surround right</text>
                </td>
            </tr>
            <tr>
                <td>5.1</td>
                <td>
                    <text class="mark">0: L: left</text><br/>
                    <text class="mark">1: R: right</text><br/>
                    <text class="mark">2: C: center</text><br/>
                    <text class="mark">3: LFE: subwoofer</text><br/>
                    <text class="mark">4: SL: surround left</text><br/>
                    <text class="mark">5: SR: surround right</text>
                </td>
            </tr>
        </table>
        
        <h2>Заключение</h2>
        <p>В тази част разгледахме какво представлява уеб аудиото и как то работи на чисто концептуално ниво. В следващата част ще се навлезем в повече детайли как се реализират ефекти като този:</p>
        <a class="btn" onclick="startLowPass()">LOW PASS EFFECT</a>

        <h1>Въведение в Web Audio API</h1><hr/>
        <p>Досега главно разглеждахме какви са принципите зад Web Audio API. Нека започнем с един елементарен пример:
        <pre class="prettyprint">
            <code class="language-javascript">
let bufferSize = 4096;

function getLowPassEffect(audioCtx) {
    let lastOut = 0.0;

    let node = audioCtx.createScriptProcessor(bufferSize, 1, 1);

    node.onaudioprocess = function(e) {
        let input = e.inputBuffer.getChannelData(0);
        let output = e.outputBuffer.getChannelData(0);

        for (let i = 0; i < bufferSize; ++i) {
            output[i] = (input[i] + lastOut) / 2.0;
            lastOut = output[i];
        }
    }

    return node;
};

            </code>
        </pre>
        В общи линии това е структурата на един аудио филтър.
        </p>
        <p>
            В предната част се запознахме с това какво представлявата AudioBuffer-ите и, че едно от свойствата им е дължина. Тази дължина трябва да бъде подбрана по оптимален начин защото тя влияе на това, колко често <i>изкарваме звук</i>, т.е. ако е твърде къса, то звука ще се застъпва и овърта, а пък ако е твърде дълга то звука ще се накъсва. Изчислено е, че около <b>4096</b> е оптималната стойност. 
            <pre class="prettyprint"><code class="language-javascript">
let bufferSize = 4096;
            </code></pre>
        </p>
        <p>
            В този пример дефинираме наш filter node от тип scriptProcessor, който позволява да използваме специфична логика за да постигнем това, което искаме. В случая се възползваме от това, че филтърната функция е closure и използваме външна променлива, в която на всяко завъртане на цикъла запазваме предната честота на звука. Така няма накъсване между изпълнението на отделните audio buffer-и. Така спазваме базовия шаблон на всеки аудио филтър - получаваме два масива, съответно за вход и изход, циклим по входния масив като манипулираме всяка извадка (sample) и я записваме обратно в изходния масив.
        </p>
        <p>В общи линии този ефект е от по-скучните и можете да го чуете като натиснете бутона отдолу. В следващите глави ще разгледаме няколко по-интересни ефекта.</p>
        <a class="btn" onclick="startLowPass()">LOW PASS EFFECT</a>
        <h2>Pinking filter</h2>
    </div>


<script src="pkg/audioContext.js"></script>
<script src="pkg/soundPlayer.js"></script>
<script src="pkg/lowPass.js"></script>
</body>
</html>